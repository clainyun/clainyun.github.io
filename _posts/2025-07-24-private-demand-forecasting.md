---
title: "수요 예측 실습 및 사례 분석"
excerpt: "수요 예측의 다양한 기법들로 실습을 진행한다"

categories:
  - LG Aimers
  - AI Essential Course
tags:
  - [LG CNS, LG Aimers, 모델학습]

permalink: /private/91f2bd2e39b4e/

toc: true
toc_sticky: true

date: 2025-07-24
last_modified_at: 2025-07-24
---
<!-- 검색엔진 차단 -->
<meta name="robots" content="noindex, nofollow">

## 🦥 본문

수요예측의 다양한 기법들을 바탕으로 실제 사례를 가지고 사례 분석을 하고, 수요 예측을 하는 시간



실제 사례는 한국토지주택공사에서 사용했던 식사 비율 예측 데이터를 가지고

앞에서 공부했던 전통적 통계 기반 모델, 인공지능 모델, 시계열 모델 등을 활용해서

실제 코딩도 해보고 수요예측을 해보면서 성과를 측정해보는 시간을 가질 것임.




정제되지 않은 데이터가 있음. 정원 수에서 휴가자 수라든지, 출장자 수를 빼야 함.

그래서 실제로 식사를 할 수 있는 직원들의 수가 필요하고 오른쪽에는 실제 메뉴들이 주어져 있음.




Target Value 목표 값은 식사한 인원 비율 이라고 생각하면 됨.




그래서 데이터를 분석해 보면 이론 시간에 배웠던 추세를 볼 수 있음. 빨간색 꺾은 선 그래프는 실제 인원들이 증가하고 있다는 것을 알 수 있음.

파란색 막대는 실제로 식사를 한 비율이다. 식사를 하는 비율이 감소 하다가 2019년 부터 다시 증가 하는 추세를 보임. 이유는 알 수 있지만 추세를 보인다는 것은 알 수 있다.




계절성이 존재함.




요일별로도 계절성이 나타나고 있음.



그래서 월별 계절성과 요일별 계절성 두 가지가 존재 한다는 것을 먼저 이해해야 한다.

우리가 데이터 분석을 하기 위해서는 데이터를 이해하는 작업이 굉장히 중요함



예측 전에 데이터를 이해하는 것의 중요성은 예측모델 적용 전에 시계열 데이터의 기본구조와 특성 파악이 필수임

제일 중요한 것이 추세가 있는지 계절성이 있는지 불규칙성만 존재 하는지 확인해야함.



데이터를 이해하지 않고 데이터의 구조를 모르고, 모델을 기계적으로 적용하면 

오적합이나 과소적합, 과대적합이 발생할 수 있음.

✅ 1. 오적합 (Misfit)
💡 개념
데이터의 구조를 잘못 이해해서 모델을 '엉뚱하게' 적용하는 것

예시
선형 관계가 아닌데 선형 모델을 적용함
→ 실제로는 곡선인데, 직선을 억지로 그려서 예측함
결과
데이터의 본질을 잘못 잡음 → 어떤 유형이든 예측 성능이 떨어짐
과소적합이든 과대적합이든 전부 포함될 수 있음
→ 일종의 ‘잘못된 모델 선택’이라고 보면 됩니다.
✅ 2. 과소적합 (Underfitting)
💡 개념
모델이 너무 단순해서 데이터의 패턴을 못 따라감

예시
시험 문제를 외워야 하는데 단어만 기억하는 수준
날씨에 따라 아이스크림 판매가 늘어나는 데이터인데, 그냥 “항상 평균만 예측하는 모델”을 씀
결과
훈련 데이터도 예측 못 함
성능이 전반적으로 낮음
시각 예시
아래처럼 데이터가 곡선인데 직선을 억지로 씌운 경우
(단순 모델 → 너무 많은 걸 놓침)

(출처: 위키피디아)
✅ 3. 과대적합 (Overfitting)
💡 개념
모델이 너무 복잡해서 훈련 데이터에 지나치게 맞춰버리는 것

예시
시험을 보기 위해 예상문제만 완벽하게 외움 → 실제 시험에선 조금만 바뀌어도 틀림
머신러닝 모델이 훈련 데이터의 '노이즈(잡음)'까지 외워버림
결과
훈련 데이터는 엄청 잘 맞추지만, 실제 예측(테스트)은 매우 약함
모델이 일반화되지 않음 (실제 데이터에 적용하면 실패)
그래서 정확한 모델 선택과 튜닝을 위하여 데이터 특성에 대한 이해로부터 적절한 데이터의 전처리 작업이 필요하고, 

필요하면 추가 변수들을 고려해야 함.




메뉴 지수 라는 거는 다른 수요예측에는 없음. 식수인원을 예측할 때 나오는 방법으로 쓸 수 있음. 메뉴지수, 또는 선호 지수라고 하는데 임의로 이름을 붙임.

메뉴 종류에 따라서 어떠한 직원들은 채식주의자가 있을 수도 있고 어떤 직원들은 해산물을 선호 하는 직원이 있고 싫어하는 직원이 있을 것임.

그래서 크게 네 가지로 분류했음.




고기가 있을 때 없을 때 채소가 있을 때 없을 때에 대한 수요가 차이가 나기 때문에 우리가 메뉴 지수라는 것을 여러가지로 고안할 수 있지만 가장 간단한 방법은

육류가 포함된 메뉴가 나왔을 때 1, 해산물 요리가 포함 됐을 때 1, 채소가 포함 됐을 때 1인데

아까 본 결과로 해산물과 채소가 포함된 경우에는 다소 수요가 떨어짐. 그래서 -1을 곱해서 빼주는 것이다.



그래서 예시와 같이 육류는 없고 해산물이 있는 경우에는 메뉴 지수가 -1이라고 해서

상대적으로 식수 수요가 적을 것으로 예측 하겠다는 것임.



그래서 계절 지수 와 메뉴 지수 또는 선호 지수 이것들을 동시에 다 고려하겠다는 것임.




또 다른 방법은 중식 메뉴의 메인 메뉴를 추출해서 각 메인 메뉴가 나왔을 때 식사 비율의 평균으로 선호지수(메뉴지수)을 산출할 수 있는데,

예를 들어 왼쪽에 데이터를 보면 과거의 훈제 오리구이 라는 메뉴가 나왔을 때 식사 비율이 되는데,

식사 비율에 대해서 평균을 뽑아보니까 41.7% 정도 나왔음



즉 이 메뉴가 나왔을 때 식사 비율이 42% 정도인데 42%는 전체 평균에 비해서는 높음.

전체 평균은 37% 정도로 직원이 천명 있으면 평균적으로 370 명이 선호 식수를 했는데 훈제 오리구이는 417명이 식수를 한거니까 상대적으로 높은 것이다.

그래서 이런 것도 선호지수로 구해서 활용할 수 있음




그리고 외부 요인 및 파생 변수로 활용할 수 있음. 예측 정확도 향상에 기여할 수 있는 변수들을 찾겠다는 것임.

그래서 실습에서는 메뉴 선호도를 반영해서 메인 메뉴 세가지에 대한 선호 지수를 산출하기로 했음.

그리고 그에 따른 중식계에 대한 데이터를 뽑았다




파생 변수 실습을 보면 데이터 전처리 작업이 필요함. 위처럼 날짜를 변환하는 것이 데이터의 전처리 작업임.








파생 변수를 생성시키기 위한 실습임. 지수를 계산하는 코드를 참고 하면 된다.

이것은 데이터를 불러와서 실제로 학습시키는 과정임.






그래서 우리는 주어진 데이터를 활용할건데, 마지막 300일은 실제 식사 비율이 주어져 있다.

하지만 우리가 그것을 모른다고 가정하고 예측을 해 볼것임.

그러면 300 일간의 마지막 데이터는 예측이 실제 발생한 거니까 얼마나 잘 예측 했는지 판단 하는 지표가 될 것임.



그래서 위에 나와있는 5가지 모델을 가지고 비교해볼 거다.

정량적 평가는 MAE(평균 절대 오차, 수요 예측치와 실제 값의 차이의 절대값), RMSE(평균 제곱근 오차, 오체 제곱의 합)

선 그래프를 활용한 오른쪽 그래프를 보면 대략적으로 예측이 잘 됐구나, 못 했구나를 평가 할 수 있음.






기존에 주어진 데이터 셋에 대해서 최소 제곱법을 이용해서 최적의 계수들을 학습 시킬 것임.

Statsmodels 라이브러리 사이트에 들어가면 자세한 코드가 있는데 그 코드를 활용할 거임.







회귀모델에 넣을 변수들을 지정함. 예측하고자 하는 목표는 식사 비율.



머신러닝에서 스케일링을 해야 하는 이유
어떤 특성은 1000 단위
어떤 특성은 0.1 단위라면
머신러닝은 숫자 크기만 보고 중요도를 착각해요.

→ 그래서 백분율처럼, 스케일링으로 모든 데이터를 같은 기준(예: 0~1)으로 맞춰주는 거예요.
이러면 기계가 공정하게 비교할 수 있어요.





R-squared(결정계수) 값이 0.695가 나옴. 결정계수는 모델이 얼마나 잘 설명하는지, 즉 설명력을 나타내는 지표

그래서 1에 가까울수록 예측이 잘 맞음. 즉, 회귀분석에서 R-squared 라는 것은 변수들이 얼마나 종속 변수를 잘 설명 하는가 이다.

보통 70% 정도가 넘으면 굉장히 잘 설명 했다고 볼 수 있음.

그리고 변수의 영향력인 p 값이 0.05 이하이면 해당 계수가 유의미 하다고 판단. 각 종속 변수의 유의미한 정도를 이 결과표를 보고 확인 할 수 있음.




성능평가는 앞에서보다는 작은 52% 값이 나옴.

설명력이 52% 정도면 수요예측을 못 했다고 하기에도 어렵고 잘했다고 하기에도 조금 아쉬운 점수임.




파란색이 300일 동안의 실제 값이고, 주황색이 회귀분석을 사용해서 예측한 값이다.




두 번째로는 시계열 예측 모델 중에서 ARIMA 방법을 사용해서 예측할 것임.

p, d, q 의 조합을 찾는 방법은 크게 두 가지.




계절성과 추세를 반영하는 시계열 수요 예측 모델인 SARIMA를 사용

물론 홀트-윈터스 방법, Prophet 방법을 다 사용할 수 있는데 SARIMA를 사용하기 위해서 데이터 전처리 하는 방법에 대한 코드가 있음.

그리고 앞에서와 마찬가지로 일자를 분류 시키는 학습용/검증용 데이터 분할 방법이 있다.




그리고 탐색 범위를 지정함. p, d, q를 예측하기 위해서 여기서는 그래서 그 이들 설치를 통해서 찾는 과정을 구하는 코드 사용했음.

Grid Search를 쓰기 위해서는 p, d, q의 범위, 최소값과 최대값을 주고 그 범위내에서 최적의 조합을 찾아 내라고 하는 것이다.

그래서 Grid Search를 통해서 찾는 과정을 구하는 코드이다. 




그리고 마지막에 찾았던 p, d, q를 사용해서 학습 시키고 마지막으로 식사 비율을 예측 하라는 코드임.




그래서 성능 평가를 했는데 아쉽게도 결과가 좋게 나오진 않았음.

그 이유는 SARIMA는 시계열의 주간 패턴은 어느 정도 잘 예측 하고 있으나 예측값이 일정한 형태로 반복 되며 실제의 비선형적 변동성을 충분히 반영 하지 못했기 때문이라고 평가 하고 있음.




파란색이 실제 식사 비율이고 주황색이 SARIMA를 사용한 예측임. 나름대로 패턴은 예측 하려고 노력을 했지만 괴리가 있다는 것을 볼 수 있음. 그래서 SARIMA 같은 경우에는 이 예측에 적합하지 않음.

SARIMA가 안 좋다는 게 아니라 데이터에 따라서 어떨 때는 SARIMA가 잘 예측할 수도 있고, 어떨 때는 Prophet이 잘 에측할 수도 있고다를 수 있다는 것을 명심해야 함.




그리고 머신러닝 모델은 앞에서 봤던 거와 같이 랜덤 포레스트 모델을 사용하도록 할 거임. 

랜덤 포레스트 모델을 사용하려면 다양한 파라미터를 설정해줘야 한다.

n_estimators(생성할 트리의 개수), max_depth(트리의 최대 깊이)

depth는 트리 하나가 얼마나 깊게 파고들지를 정하는 기준.

어쨌든 이 파라미터를 먼저 찾아 내야 한다. 그래서 파라미터 찾는 방법은 GridSearchCV, RandomizedSearchCV 등 다양한 방법들이 개발중임.



최적의 파라미터를 찾아서 학습 시킨 다음 예측을 수행함. 이 라이브러리는 밑에 있는 사이트 에서 다운로드 받을 수 있음. 

서울대학교 문일경 교수님 연구실 홈페이지에 이런 것들을 모두 다운로드 받아서 저장해놓았음.




앞에서랑 마찬가지로 데이터 전처리 작업이 필요함. 학습용/검증용 데이터를 분할하는 과정이 필요

그런 코드들을 정리해 놓았다.




그리고 최적 파라미터 조합을 탐색 하는 부분은 생략했지만, 코드에는 포함되어 있음.

마지막으로 성능 평가를 시행 했는데 영향력이 꽤 높게 나왔음

62% 정도 나왔다는 것은 꽤 잘 예측했다는 것임.






그런데 수요예측 모델 중에서 하이브리드 모델이 좋다고 했었는데, 이제 그 하이브리드 모델을 사용해보도록 하겠다.




홀트-윈터스와 랜덤 포레스트를 합친 방법이다.





그러고 성능 평가를 시행 했는데 MSE, 결정 계수 같은 모든 것이 좋게 나옴. MSE는 작으면 작을수록 좋은데 하이브리드 모델은 거의 0에  가까운 값이 나왔음.

하이브리드 모델의 결정 계수 값은 90%가 넘음. 




검정색이 실제 식수 비율. 그래서 이 주어진 데이터에 대해서는 하이브리드 모델이 굉장히 수요예측을 잘 했다는 것이다.

아마 다른 데이터의 경우에서도 추세나 계절성을 잘 파악한 다음에 시계열 분석방법과 랜덤 프레스트방법 같은 것을 혼합 하는 하이브리드 모델을 사용하면 수요예측 경진대회 같은 곳에서 좋은 결과를 얻을 것임.




마지막으로 참고를 하기 위해서 딥러닝 모델을 설명 할 것임. 딥러닝 모델도 시계열 데이터의 흐름과 추세를 학습하는데 강력한 기법 중 하나다.



그리고 과적합을 방지하고 최적 학습 시점을 제어하는데 필요한 방법임. 결국 하이퍼파라미터의 설정이 모델 성능에 중대한 영향을 미친다.

노드 수, 모델 구조, optimizer 및 learning rate 등에 따라서 결과가 달라짐.

딥 러닝은 시행착오가 많이 필요하다. 그냥 인공지능 기법을 쓰면 무조건 좋은 결과가 나올 거다 라고 하는 것은 착각이다

인공지능 모델을 잘 적용 하기 위해서는 시행착오가 필요해서 결국 이런 하이퍼파라미터를 잘 찾아 내야 되는 작업이 필요하다.

지금 보면 예측이 그렇게 잘 맞지는 않는다.




그 이유는 딥 러닝 코드를 보면 결정 계수 값이 39% 밖에 나오지 않았음. 회귀분석은 50%가 넘었는데 아쉬운 결과임.

딥 러닝 모델이 안 좋다는 게 아니라 데이터 셋의 이러한 파라미터 설정 하에서는 좋지 않은 결과가 나왔다는 거다.

그러나 충분한 학습과 시행착오를 통해서 하이퍼파라미터의 조합을 잘 찾아 내면 결정계수 값이 60% 이상으로 나올거다.




유의미한 요인선택 및 추가는 물론 인공지능 기법을 사용하면 모델이 알아서 찾아주지만 코드에 맡길 것이 아니라,

우리가 데이터를 보고 어떤 요인들들이 수요 예측에 영향을 미치는가를 찾아내서 인공지능 기법이 제대로 변수들을 포함하고 있는가를 확인 해주는 절차들이 필요하다.



그리고 도메인 지식을 바탕으로 피처 엔지니어링을 수행하는 것을 권장함.

그리고 앞에서도 말한 하이퍼파라미터 튜닝, 좋은 하이퍼파라미터를 찾아내고 계산 하는 과정을 통해서 수요 예측의 성능이 개선 된다.

그래서 Grid Search, Random Search, Optuna 라이브러리 등 활용해서 좋은 하이퍼파라미터들의 조합을 찾아내자.



그리고 앙상블 모델에 대해서 다루지 않았지만 하이브리드 모델이나 앙상블 모델을 사용할 것을 추천 함

그리고 서로 다른 예측 모델을 조합하여 예측 정확도를 향상 시킬 수 있기 때문에

한가지 방법보다는 몇 가지 방법을 보고 서로 비교해서 어떤 방법이 이 데이터에 대해서 수요 예측을 잘 하는가를 찾아내는 것도 굉장히 좋은 방법이라고 생각한다.
